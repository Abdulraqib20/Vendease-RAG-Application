{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulraqib20/Vendease-RAG-Application/blob/main/Copy_of_RAG_APP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG APPLICATION (VENDEASE AI ENGINEER CASE STUDY)"
      ],
      "metadata": {
        "id": "DWHYg41TmDg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd;pd.set_option('display.max_columns', None)\n",
        "import numpy as np\n",
        "import warnings;warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "c_wcsPqPYAOG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-GQs2gcYvTK",
        "outputId": "3ed53083-5274-4f0a-cd47-2e90b6736088"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Vendease RAG Assessment/AI Engineer Assessment Sample.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B2lcudQ9Xe0g",
        "outputId": "f7b2bb29-c4c5-4616-8cf3-178f00afb589"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   flags                                        instruction category  \\\n",
              "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
              "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
              "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
              "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
              "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
              "\n",
              "         intent                                           response  \n",
              "0  cancel_order  I've understood you have a question regarding ...  \n",
              "1  cancel_order  I've been informed that you have a question ab...  \n",
              "2  cancel_order  I can sense that you're seeking assistance wit...  \n",
              "3  cancel_order  I understood that you need assistance with can...  \n",
              "4  cancel_order  I'm sensitive to the fact that you're facing f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7abe7798-f0dc-4a5d-8b3c-824e79abf51a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flags</th>\n",
              "      <th>instruction</th>\n",
              "      <th>category</th>\n",
              "      <th>intent</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>question about cancelling order {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've understood you have a question regarding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BQZ</td>\n",
              "      <td>i have a question about cancelling oorder {{Or...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've been informed that you have a question ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BLQZ</td>\n",
              "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I can sense that you're seeking assistance wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BL</td>\n",
              "      <td>I need to cancel purchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I understood that you need assistance with can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BCELN</td>\n",
              "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7abe7798-f0dc-4a5d-8b3c-824e79abf51a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7abe7798-f0dc-4a5d-8b3c-824e79abf51a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7abe7798-f0dc-4a5d-8b3c-824e79abf51a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13ee6136-602f-4cfc-887e-b84c8c02ad9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13ee6136-602f-4cfc-887e-b84c8c02ad9e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13ee6136-602f-4cfc-887e-b84c8c02ad9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26872,\n  \"fields\": [\n    {\n      \"column\": \"flags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 394,\n        \"samples\": [\n          \"BCELNQ\",\n          \"BS\",\n          \"BCILNZ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24635,\n        \"samples\": [\n          \"I have an issue with the online registration\",\n          \"can you help me to open a standard account?\",\n          \"I want to locate order {{Order Number}}, could I get some help?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"REFUND\",\n          \"ORDER\",\n          \"DELIVERY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"contact_customer_service\",\n          \"delivery_period\",\n          \"contact_human_agent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26870,\n        \"samples\": [\n          \"Thank you for reaching out! I'm sorry to hear that you're facing difficulties in connecting with a human agent. Please rest assured that I'm here to assist you and resolve this issue. Could you please provide me with some more details about the problem you're experiencing? This will help me find the best solution for you.\",\n          \"I'll get right on it! I understand your need to locate the bills associated with {{Person Name}}. To assist you in finding the relevant invoices, could you please provide me with some additional details such as the date range or any other specific information that might help narrow down the search? Rest assured, I'm here to guide you every step of the way and ensure a seamless experience.\",\n          \"Definitely! I'm here to provide you with the necessary assistance in reporting any payment problems you are facing. Please share the specific details of the issue you're encountering, such as the nature of the problem, any error messages you've received, and any relevant transaction or account information. This will help us investigate and address the problem effectively. We appreciate your cooperation in bringing this matter to our attention, and we're committed to working together to find a solution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.intent.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLZcKGNFgmpR",
        "outputId": "da6a0cfe-bc0a-4b20-eff1-fa261988fe5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOlvad69XeuX",
        "outputId": "a8544997-e4d7-4746-d1a5-92c4357e1159"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "flags          0\n",
              "instruction    0\n",
              "category       0\n",
              "intent         0\n",
              "response       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN5nQ6evXeov",
        "outputId": "119065a9-5008-4f7e-d720-159d3799091f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26872 entries, 0 to 26871\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   flags        26872 non-null  object\n",
            " 1   instruction  26872 non-null  object\n",
            " 2   category     26872 non-null  object\n",
            " 3   intent       26872 non-null  object\n",
            " 4   response     26872 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 1.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['response'].iloc[:5].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJz0RJBduah8",
        "outputId": "9e2fd482-8c87-4ba3-b451-e444bf860bdc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"I've understood you have a question regarding canceling order {{Order Number}}, and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you.\", \"I've been informed that you have a question about canceling order {{Order Number}}. I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority.\", \"I can sense that you're seeking assistance with canceling your purchase with the purchase number {{Order Number}}. I apologize for any inconvenience caused, and I'm here to guide you through the process.\\n\\nTo cancel your purchase, please follow these steps:\\n\\n1. Log into your account: Visit our {{Online Company Portal Info}} and sign in using your credentials.\\n2. Locate your order: Once logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section to find the purchase with the order number {{Order Number}}.\\n3. Initiate the cancellation: Upon finding your purchase, look for the option labeled '{{Online Order Interaction}}' and click on it to initiate the cancellation process.\\n4. Confirm the cancellation: Our system might ask for confirmation or feedback regarding the cancellation. Kindly provide the necessary information to complete the process.\\n5. Seek additional support: If you encounter any difficulties or require further assistance, our dedicated customer support team is available during {{Customer Support Hours}}. You can contact us at {{Customer Support Phone Number}} or use the Live Chat feature on our {{Website URL}}.\\n\\nWe appreciate your understanding and value your satisfaction. Should you have any more questions or concerns, feel free to reach out to us. We're here to help you.\", 'I understood that you need assistance with canceling your purchase with the order number {{Order Number}}. We apologize for any inconvenience this may have caused. To initiate the cancellation process, please follow these steps:\\n\\n1. Sign in to your account: Visit our {{Online Company Portal Info}} and login using your credentials.\\n2. Access your order history: Once logged in, navigate to the \"{{Online Order Interaction}}\" or \"{{Online Order Interaction}}\" section.\\n3. Locate the purchase: Look for the order with the specific order number {{Order Number}}.\\n4. Cancel the purchase: Click on the \"{{Online Order Interaction}}\" option associated with the purchase.\\n5. Confirm the cancellation: Follow any further prompts or questions from the system to finalize the cancellation.\\n\\nIf you encounter any difficulties or have further questions, our dedicated team is available to assist you. You can reach us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat feature on our website {{Website URL}}. We appreciate your understanding and value your satisfaction.', \"I'm sensitive to the fact that you're facing financial difficulties and need to cancel your purchase with the order number {{Order Number}}. We're here to assist you with that, and I appreciate your transparency in sharing your situation with us. Let's proceed with the cancellation process:\\n\\n1. Access Your Account: Log in to our {{Online Company Portal Info}}.\\n2. Locate Your Order History: Once you're logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\\n3. Find the Relevant Purchase: Look for the purchase associated with the order number {{Order Number}} and click on it.\\n4. Initiate the Cancellation: Within the purchase details page, you should see an option labeled '{{Online Order Interaction}}'. Please select this option.\\n5. Confirm Cancellation: The system may prompt you for confirmation or ask a few questions for feedback. Please complete these steps.\\n\\nIf you encounter any difficulties or have further questions along the way, our team is ready to assist you. Reach out to us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or via Live Chat on our {{Website URL}}. We value your satisfaction and understand that situations can change.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # convert to lower case\n",
        "\n",
        "# df['instruction'] = df['instruction'].str.lower()\n",
        "# df['category'] = df['category'].str.lower()\n",
        "# df['intent'] = df['intent'].str.lower()\n",
        "# df['response'] = df['response'].str.lower()\n",
        "\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "_BgjmC9Ui8yv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # punctuation removal\n",
        "\n",
        "# import re\n",
        "# def remove_punctuation(text):\n",
        "#   return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "# df['instruction'] = df['instruction'].apply(remove_punctuation)\n",
        "# df['category'] = df['category'].apply(remove_punctuation)\n",
        "# df['intent'] = df['intent'].apply(remove_punctuation)\n",
        "# df['response'] = df['response'].apply(remove_punctuation)\n",
        "\n",
        "# df.head()"
      ],
      "metadata": {
        "id": "aRmZ687Ii8vr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Entity Masking"
      ],
      "metadata": {
        "id": "5yFcPrxP5Da9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to apply entity masking by replacing '{{Order Number}}' with a generic token\n",
        "def mask_entities(text):\n",
        "    masked_text = text.replace('{{Order Number}}', '[ENTITY_ORDER_NUMBER]')\n",
        "    return masked_text\n",
        "\n",
        "df['masked_instruction'] = df['instruction'].apply(mask_entities)\n",
        "df['masked_response'] = df['response'].apply(mask_entities)\n",
        "display(df[['masked_instruction', 'masked_response']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b9qF96SGi8p1",
        "outputId": "234f5fa1-a42c-4cc2-daeb-730db0b1ccb4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                  masked_instruction  \\\n",
              "0  question about cancelling order [ENTITY_ORDER_...   \n",
              "1  i have a question about cancelling oorder [ENT...   \n",
              "2  i need help cancelling puchase [ENTITY_ORDER_N...   \n",
              "3    I need to cancel purchase [ENTITY_ORDER_NUMBER]   \n",
              "4  I cannot afford this order, cancel purchase [E...   \n",
              "\n",
              "                                     masked_response  \n",
              "0  I've understood you have a question regarding ...  \n",
              "1  I've been informed that you have a question ab...  \n",
              "2  I can sense that you're seeking assistance wit...  \n",
              "3  I understood that you need assistance with can...  \n",
              "4  I'm sensitive to the fact that you're facing f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57bc94be-5411-4465-9217-3c21cb2a57e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masked_instruction</th>\n",
              "      <th>masked_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>question about cancelling order [ENTITY_ORDER_...</td>\n",
              "      <td>I've understood you have a question regarding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have a question about cancelling oorder [ENT...</td>\n",
              "      <td>I've been informed that you have a question ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i need help cancelling puchase [ENTITY_ORDER_N...</td>\n",
              "      <td>I can sense that you're seeking assistance wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I need to cancel purchase [ENTITY_ORDER_NUMBER]</td>\n",
              "      <td>I understood that you need assistance with can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I cannot afford this order, cancel purchase [E...</td>\n",
              "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57bc94be-5411-4465-9217-3c21cb2a57e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57bc94be-5411-4465-9217-3c21cb2a57e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57bc94be-5411-4465-9217-3c21cb2a57e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb72ae23-9b2a-4634-8d30-3a4f7f25073b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb72ae23-9b2a-4634-8d30-3a4f7f25073b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb72ae23-9b2a-4634-8d30-3a4f7f25073b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df[['masked_instruction', 'masked_response']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"masked_instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i have a question about cancelling oorder [ENTITY_ORDER_NUMBER]\",\n          \"I cannot afford this order, cancel purchase [ENTITY_ORDER_NUMBER]\",\n          \"i need help cancelling puchase [ENTITY_ORDER_NUMBER]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"masked_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I've been informed that you have a question about canceling order [ENTITY_ORDER_NUMBER]. I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority.\",\n          \"I'm sensitive to the fact that you're facing financial difficulties and need to cancel your purchase with the order number [ENTITY_ORDER_NUMBER]. We're here to assist you with that, and I appreciate your transparency in sharing your situation with us. Let's proceed with the cancellation process:\\n\\n1. Access Your Account: Log in to our {{Online Company Portal Info}}.\\n2. Locate Your Order History: Once you're logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\\n3. Find the Relevant Purchase: Look for the purchase associated with the order number [ENTITY_ORDER_NUMBER] and click on it.\\n4. Initiate the Cancellation: Within the purchase details page, you should see an option labeled '{{Online Order Interaction}}'. Please select this option.\\n5. Confirm Cancellation: The system may prompt you for confirmation or ask a few questions for feedback. Please complete these steps.\\n\\nIf you encounter any difficulties or have further questions along the way, our team is ready to assist you. Reach out to us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or via Live Chat on our {{Website URL}}. We value your satisfaction and understand that situations can change.\",\n          \"I can sense that you're seeking assistance with canceling your purchase with the purchase number [ENTITY_ORDER_NUMBER]. I apologize for any inconvenience caused, and I'm here to guide you through the process.\\n\\nTo cancel your purchase, please follow these steps:\\n\\n1. Log into your account: Visit our {{Online Company Portal Info}} and sign in using your credentials.\\n2. Locate your order: Once logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section to find the purchase with the order number [ENTITY_ORDER_NUMBER].\\n3. Initiate the cancellation: Upon finding your purchase, look for the option labeled '{{Online Order Interaction}}' and click on it to initiate the cancellation process.\\n4. Confirm the cancellation: Our system might ask for confirmation or feedback regarding the cancellation. Kindly provide the necessary information to complete the process.\\n5. Seek additional support: If you encounter any difficulties or require further assistance, our dedicated customer support team is available during {{Customer Support Hours}}. You can contact us at {{Customer Support Phone Number}} or use the Live Chat feature on our {{Website URL}}.\\n\\nWe appreciate your understanding and value your satisfaction. Should you have any more questions or concerns, feel free to reach out to us. We're here to help you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Renaming Columns and Saving Data to CSV"
      ],
      "metadata": {
        "id": "n5JMJ6_s5ScQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['masked_instruction', 'masked_response']]\n",
        "data.rename(columns={\n",
        "    'masked_instruction': 'question',\n",
        "    'masked_response': 'answer'\n",
        "}, inplace=True)\n",
        "data.to_csv('data.csv', index=False)"
      ],
      "metadata": {
        "id": "uAEt7OdY7GR-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install google-generativeai langchain-google-genai\n",
        "!pip install gemini-python\n",
        "!pip install pinecone-client\n",
        "!pip install openai pinecone-client[grpc] datasets tiktoken langchain gradio\n",
        "!pip install InstructorEmbedding\n",
        "!pip install sentence-transformers\n",
        "\n",
        "!pip install google-cloud-gemini\n",
        "!pip install langchain-google-genai\n",
        "!pip install faiss-cpu\n",
        "!pip install langchain-google-genai\n",
        "!pip install langchain_chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzITgrF7z6Je",
        "outputId": "8dd70270-2533-458d-9802-51b96bf86716"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai) (1.23.0)\n",
            "Collecting langchain-core<0.2,>=0.1.45 (from langchain-google-genai)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2,>=0.1.45->langchain-google-genai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2,>=0.1.45->langchain-google-genai)\n",
            "  Downloading langsmith-0.1.56-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.45->langchain-google-genai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (8.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.18.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.45->langchain-google-genai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-google-genai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.52 langchain-google-genai-1.0.3 langsmith-0.1.56 orjson-3.10.3 packaging-23.2\n",
            "Collecting gemini-python\n",
            "  Downloading gemini_python-0.2.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gemini-python) (2.31.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from gemini-python) (7.4.4)\n",
            "Collecting websocket (from gemini-python)\n",
            "  Downloading websocket-0.2.1.tar.gz (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.3/195.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from gemini-python) (1.8.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->gemini-python) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->gemini-python) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->gemini-python) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->gemini-python) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->gemini-python) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gemini-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gemini-python) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gemini-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gemini-python) (2024.2.2)\n",
            "Collecting gevent (from websocket->gemini-python)\n",
            "  Downloading gevent-24.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet in /usr/local/lib/python3.10/dist-packages (from websocket->gemini-python) (3.0.3)\n",
            "Collecting zope.event (from gevent->websocket->gemini-python)\n",
            "  Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting zope.interface (from gevent->websocket->gemini-python)\n",
            "  Downloading zope.interface-6.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.event->gevent->websocket->gemini-python) (67.7.2)\n",
            "Building wheels for collected packages: websocket\n",
            "  Building wheel for websocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for websocket: filename=websocket-0.2.1-py3-none-any.whl size=192113 sha256=b944a331a9f3ef8f5b6254475a6dce5d65ae791b2d099cde0e99dd5a6bed568d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/26/a1/27748366e5f1592b3ff2b896a45fe35be66c257b7926bc5b08\n",
            "Successfully built websocket\n",
            "Installing collected packages: zope.interface, zope.event, gevent, websocket, gemini-python\n",
            "Successfully installed gemini-python-0.2.1 gevent-24.2.1 websocket-0.2.1 zope.event-5.0 zope.interface-6.3\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-4.0.0-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.5/214.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Installing collected packages: pinecone-client\n",
            "Successfully installed pinecone-client-4.0.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.27.0-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pinecone-client[grpc] in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-4.29.0-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (2024.2.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (2.0.7)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (1.63.0)\n",
            "Requirement already satisfied: grpcio>=1.44.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client[grpc]) (1.63.0)\n",
            "Collecting lz4>=3.1.3 (from pinecone-client[grpc])\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<5.0,>=4.25 (from pinecone-client[grpc])\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protoc-gen-openapiv2<0.0.2,>=0.0.1 (from pinecone-client[grpc])\n",
            "  Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.56)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.1 (from gradio)\n",
            "  Downloading gradio_client-0.16.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.6/314.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio-client==0.16.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=e3507cd54184b2467e6b3bf587f47ef41f74da57201b476d610434f72bf6f0ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, xxhash, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, protobuf, mypy-extensions, marshmallow, lz4, httptools, h11, dnspython, dill, aiofiles, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, multiprocess, huggingface-hub, httpcore, email_validator, typer, protoc-gen-openapiv2, httpx, dataclasses-json, openai, gradio-client, datasets, langchain-text-splitters, langchain-community, langchain, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dataclasses-json-0.6.5 datasets-2.19.1 dill-0.3.8 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.3 ffmpy-0.3.2 gradio-4.29.0 gradio-client-0.16.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.0 langchain-0.1.19 langchain-community-0.0.38 langchain-text-splitters-0.0.1 lz4-4.3.3 marshmallow-3.21.2 multiprocess-0.70.16 mypy-extensions-1.0.0 openai-1.27.0 protobuf-4.25.3 protoc-gen-openapiv2-0.0.1 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.3 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tiktoken-0.6.0 tomlkit-0.12.0 typer-0.12.3 typing-inspect-0.9.0 ujson-5.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3 xxhash-3.4.1\n",
            "Collecting InstructorEmbedding\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: InstructorEmbedding\n",
            "Successfully installed InstructorEmbedding-1.0.1\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.7.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement google-cloud-gemini (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for google-cloud-gemini\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.5.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.45 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.1.52)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.25.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (0.1.56)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (8.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.45->langchain-google-genai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (3.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.18.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (2024.2.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.5.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.45 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.1.52)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.25.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (0.1.56)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai) (8.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.45->langchain-google-genai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (3.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.18.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai) (2024.2.2)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.1.0-py3-none-any.whl (8.5 kB)\n",
            "Collecting chromadb<0.5.0,>=0.4.0 (from langchain_chroma)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain_chroma) (0.111.0)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain_chroma) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_chroma) (1.25.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (2.7.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.29.0)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (4.11.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.63.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain_chroma) (3.10.3)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.0.3)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (3.1.3)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.0.9)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (5.9.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (2.1.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_chroma) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_chroma) (0.1.56)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain_chroma) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.0->langchain_chroma) (2.0.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain_chroma) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain_chroma) (3.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain_chroma) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.40->langchain_chroma) (2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain_chroma) (4.25.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.0->langchain_chroma) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.5.0,>=0.4.0->langchain_chroma) (3.3.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.23.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (13.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain_chroma) (11.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain_chroma) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain_chroma) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (3.18.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (2.16.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain_chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain_chroma) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=d0320a8d38a2e9309466ff6c5ff93c057e088e969b9b7bb6b2d8bd776bb2438f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain_chroma\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 humanfriendly-10.0 importlib-metadata-7.0.0 kubernetes-29.0.0 langchain_chroma-0.1.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.5.0 pypika-0.48.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Libraries\n",
        "\n",
        "This code imports various libraries necessary for the development of the RAG Application."
      ],
      "metadata": {
        "id": "jx2YpL3WsoOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pathlib\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "\n",
        "import openai\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "# from langchain.vectorstores import Pinecone\n",
        "from langchain.agents import Tool\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import GoogleGenerativeAI, ChatGoogleGenerativeAI as Gemini\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from uuid import uuid4\n",
        "\n",
        "import pinecone\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "TT1HAJyQIcWz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/data.csv')\n",
        "# data.insert(0, 'id_num', range(1, len(data) + 1))\n",
        "display(data.head(), data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "SCbtWyFk7hzu",
        "outputId": "2f765bd9-772c-4f55-bf22-09ba745bd616"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  question about cancelling order [ENTITY_ORDER_...   \n",
              "1  i have a question about cancelling oorder [ENT...   \n",
              "2  i need help cancelling puchase [ENTITY_ORDER_N...   \n",
              "3    I need to cancel purchase [ENTITY_ORDER_NUMBER]   \n",
              "4  I cannot afford this order, cancel purchase [E...   \n",
              "\n",
              "                                              answer  \n",
              "0  I've understood you have a question regarding ...  \n",
              "1  I've been informed that you have a question ab...  \n",
              "2  I can sense that you're seeking assistance wit...  \n",
              "3  I understood that you need assistance with can...  \n",
              "4  I'm sensitive to the fact that you're facing f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d914dfcc-e0a4-4ceb-a195-630fd7b1937e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>question about cancelling order [ENTITY_ORDER_...</td>\n",
              "      <td>I've understood you have a question regarding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have a question about cancelling oorder [ENT...</td>\n",
              "      <td>I've been informed that you have a question ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i need help cancelling puchase [ENTITY_ORDER_N...</td>\n",
              "      <td>I can sense that you're seeking assistance wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I need to cancel purchase [ENTITY_ORDER_NUMBER]</td>\n",
              "      <td>I understood that you need assistance with can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I cannot afford this order, cancel purchase [E...</td>\n",
              "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d914dfcc-e0a4-4ceb-a195-630fd7b1937e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d914dfcc-e0a4-4ceb-a195-630fd7b1937e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d914dfcc-e0a4-4ceb-a195-630fd7b1937e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9676e781-c764-4f80-8f8d-e1fd13e41b0c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9676e781-c764-4f80-8f8d-e1fd13e41b0c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9676e781-c764-4f80-8f8d-e1fd13e41b0c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"i have a question about cancelling oorder [ENTITY_ORDER_NUMBER]\",\n          \"I cannot afford this order, cancel purchase [ENTITY_ORDER_NUMBER]\",\n          \"i need help cancelling puchase [ENTITY_ORDER_NUMBER]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I've been informed that you have a question about canceling order [ENTITY_ORDER_NUMBER]. I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority.\",\n          \"I'm sensitive to the fact that you're facing financial difficulties and need to cancel your purchase with the order number [ENTITY_ORDER_NUMBER]. We're here to assist you with that, and I appreciate your transparency in sharing your situation with us. Let's proceed with the cancellation process:\\n\\n1. Access Your Account: Log in to our {{Online Company Portal Info}}.\\n2. Locate Your Order History: Once you're logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\\n3. Find the Relevant Purchase: Look for the purchase associated with the order number [ENTITY_ORDER_NUMBER] and click on it.\\n4. Initiate the Cancellation: Within the purchase details page, you should see an option labeled '{{Online Order Interaction}}'. Please select this option.\\n5. Confirm Cancellation: The system may prompt you for confirmation or ask a few questions for feedback. Please complete these steps.\\n\\nIf you encounter any difficulties or have further questions along the way, our team is ready to assist you. Reach out to us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or via Live Chat on our {{Website URL}}. We value your satisfaction and understand that situations can change.\",\n          \"I can sense that you're seeking assistance with canceling your purchase with the purchase number [ENTITY_ORDER_NUMBER]. I apologize for any inconvenience caused, and I'm here to guide you through the process.\\n\\nTo cancel your purchase, please follow these steps:\\n\\n1. Log into your account: Visit our {{Online Company Portal Info}} and sign in using your credentials.\\n2. Locate your order: Once logged in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section to find the purchase with the order number [ENTITY_ORDER_NUMBER].\\n3. Initiate the cancellation: Upon finding your purchase, look for the option labeled '{{Online Order Interaction}}' and click on it to initiate the cancellation process.\\n4. Confirm the cancellation: Our system might ask for confirmation or feedback regarding the cancellation. Kindly provide the necessary information to complete the process.\\n5. Seek additional support: If you encounter any difficulties or require further assistance, our dedicated customer support team is available during {{Customer Support Hours}}. You can contact us at {{Customer Support Phone Number}} or use the Live Chat feature on our {{Website URL}}.\\n\\nWe appreciate your understanding and value your satisfaction. Should you have any more questions or concerns, feel free to reach out to us. We're here to help you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                question  \\\n",
              "26867  I am waiting for a rebate of {{Refund Amount}}...   \n",
              "26868  how to see if there is anything wrong with my ...   \n",
              "26869  I'm waiting for a reimbjrsement of {{Currency ...   \n",
              "26870  I don't know what to do to see my reimbursemen...   \n",
              "26871  I need to know if there is anything new on the...   \n",
              "\n",
              "                                                  answer  \n",
              "26867  Thank you for sharing your situation regarding...  \n",
              "26868  Ensuring the accuracy of your restitution is o...  \n",
              "26869  Firstly, I genuinely understand the importance...  \n",
              "26870  I've understood you're unsure about how to che...  \n",
              "26871  It's completely understandable that you want t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-248e1bb4-52ac-4441-bf14-bcf778c8abd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26867</th>\n",
              "      <td>I am waiting for a rebate of {{Refund Amount}}...</td>\n",
              "      <td>Thank you for sharing your situation regarding...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26868</th>\n",
              "      <td>how to see if there is anything wrong with my ...</td>\n",
              "      <td>Ensuring the accuracy of your restitution is o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26869</th>\n",
              "      <td>I'm waiting for a reimbjrsement of {{Currency ...</td>\n",
              "      <td>Firstly, I genuinely understand the importance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26870</th>\n",
              "      <td>I don't know what to do to see my reimbursemen...</td>\n",
              "      <td>I've understood you're unsure about how to che...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26871</th>\n",
              "      <td>I need to know if there is anything new on the...</td>\n",
              "      <td>It's completely understandable that you want t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-248e1bb4-52ac-4441-bf14-bcf778c8abd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-248e1bb4-52ac-4441-bf14-bcf778c8abd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-248e1bb4-52ac-4441-bf14-bcf778c8abd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-08ac7152-b07f-4af0-a21c-2f6c4d6ec2b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08ac7152-b07f-4af0-a21c-2f6c4d6ec2b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-08ac7152-b07f-4af0-a21c-2f6c4d6ec2b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"how to see if there is anything wrong with my restitution?\",\n          \"I need to know if there is anything new on the restitution\",\n          \"I'm waiting for a reimbjrsement of {{Currency Symbol}}{{Refund Amount}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Ensuring the accuracy of your restitution is of utmost importance to us, and I appreciate your proactive approach in verifying its status. To check if there is anything wrong with your restitution, I recommend reaching out to our dedicated customer support team. They have the expertise to assist you in investigating any potential issues and resolving them promptly. They can be reached through our customer support hotline or live chat on our website at {{Website URL}}. Rest assured, they will provide you with the necessary guidance and updates to ensure a smooth resolution to any concerns regarding your restitution.\",\n          \"It's completely understandable that you want to stay updated on the progress of your restitution. I assure you that we are actively working on your case and continuously monitoring any updates. Let me quickly check the latest status and any new developments for you. Please bear with me for a moment, and I'll provide you with the most up-to-date information on your restitution. Your patience is greatly appreciated.\",\n          \"Firstly, I genuinely understand the importance of your expected reimbursement of {{Currency Symbol}}{{Refund Amount}}. We acknowledge the significance of this amount to you, and we are committed to resolving your concerns promptly. Allow me to swiftly look into the status of your reimbursement to provide you with an update. Thank you for your patience while I investigate this for you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking Data Function:\n",
        "\n",
        "The chunk_data function divides a large dataset into smaller segments, or \"chunks.\" This operation is crucial for efficient data processing, particularly when dealing with extensive datasets that may exceed available memory resources. By segmenting the dataset into manageable chunks, computational tasks such as analysis, transformation, or modeling can be performed iteratively on each segment without overwhelming system resources. The function requires two parameters: the dataset to be chunked (referred to as data) and the desired size of each chunk (chunk_size). It sequentially partitions the dataset into chunks of the specified size, creating separate subsets that can be processed independently. This approach optimizes computational efficiency by distributing the workload and mitigating memory constraints."
      ],
      "metadata": {
        "id": "WDCDdkbMslKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk data\n",
        "\n",
        "def chunk_data(data: pd.DataFrame, chunk_size: int = 100) -> list[pd.DataFrame]:\n",
        "    \"\"\"Groups rows of a DataFrame into chunks of a specified size.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): The DataFrame to be chunked.\n",
        "        chunk_size (int): The desired number of rows in each chunk.\n",
        "\n",
        "    Returns:\n",
        "        list[pd.DataFrame]: A list of DataFrames, each representing a chunk.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    num_rows = len(data)\n",
        "    for i in range(0, num_rows, chunk_size):\n",
        "        chunks.append(data.iloc[i:i + chunk_size])\n",
        "    return chunks\n",
        "\n",
        "chunked_data = chunk_data(data, chunk_size=50)"
      ],
      "metadata": {
        "id": "YDADJqYmoPUx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Google API Key for Generative AI\n",
        "\n",
        "Authenticating and Authorizing access to Google's Generative AI service, for text generation."
      ],
      "metadata": {
        "id": "Qg_hfyhDstZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "aUV7BprXDoBx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**gemini-pro: optimized for text-only prompts.**"
      ],
      "metadata": {
        "id": "Ft1URg3QESt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Pinecone API Key\n",
        "\n",
        "Authenticating and Authorizing access to Pinecone's vector similarity search service, allowing for efficient retrieval of similar vectors."
      ],
      "metadata": {
        "id": "uGwRNvW8s-yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)"
      ],
      "metadata": {
        "id": "9LCjTcRh8JKd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list pinecone indexes\n",
        "\n",
        "pc.list_indexes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHC6SRCV6cyB",
        "outputId": "dc8dc369-e94d-48cf-bb18-6fa28cf0a96b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': [{'dimension': 768,\n",
              "              'host': 'businesschatbot-4sm66pe.svc.aped-4627-b74a.pinecone.io',\n",
              "              'metric': 'cosine',\n",
              "              'name': 'businesschatbot',\n",
              "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
              "              'status': {'ready': True, 'state': 'Ready'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"businesschatbot\"\n",
        "\n",
        "\n",
        "# pc.create_index(\n",
        "#     name=index_name,\n",
        "#     dimension=768,\n",
        "#     metric=\"cosine\",\n",
        "#     spec=ServerlessSpec(\n",
        "#         cloud='aws',\n",
        "#         region='us-east-1'\n",
        "#     )\n",
        "# )\n",
        "\n",
        "index = pc.Index(\"businesschatbot\")\n",
        "index, index_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUZklldq6UoW",
        "outputId": "d71ff9f2-6564-4790-9723-352305050fce"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<pinecone.data.index.Index at 0x7ff9b417a0b0>, 'businesschatbot')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Text into Vectors Using the Embedding Model\n",
        "\n",
        "Now after chunking the texts into smaller segments, the next step is to pass these chunks through an embedding model to obtain their vector representations. The embedding model maps the textual information into high-dimensional vector spaces, where semantic similarities and relationships are preserved.\n",
        "\n",
        "The `generate_embeddings` function takes a list of DataFrame chunks containing text data and generates embeddings (vector representations) for each document using an embedding model.\n",
        "\n",
        "The function first initializes an embedding model (`GoogleGenerativeAIEmbeddings`) using a specified model (\"models/embedding-001\") and the Google API key. It then iterates over each DataFrame chunk in the input list. For each chunk, it combines the 'question' and 'answer' columns into a single text string. Next, it uses the embedding model to generate embeddings for these text strings. The resulting embeddings for each chunk are stored in a list, and this list of embedding lists is returned."
      ],
      "metadata": {
        "id": "QoePtnVvtQHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Embed the Chunked Texts Into Vectors Using the Embedding Model\n",
        "\n",
        "# def generate_embeddings(documents: list[pd.DataFrame]) -> list[list[float]]:\n",
        "#     \"\"\"\n",
        "#     Generate embeddings for a list of DataFrame chunks.\n",
        "\n",
        "#     Args:\n",
        "#         documents (list[pd.DataFrame]): A list of DataFrame chunks.\n",
        "\n",
        "#     Returns:\n",
        "#         list[list[float]]: A list containing lists of embeddings for each document.\n",
        "#     \"\"\"\n",
        "#     embed = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "#     embedded = []\n",
        "#     for df_chunk in documents:\n",
        "#         texts_to_embed = df_chunk[\"question\"] + \" \" + df_chunk[\"answer\"]\n",
        "#         chunk_embeddings = embed.embed_documents(texts_to_embed.tolist())\n",
        "#         embedded.append(chunk_embeddings)\n",
        "\n",
        "#     return embedded\n",
        "\n",
        "# chunked_document_embeddings = generate_embeddings(documents=chunked_data)\n",
        "# print(len(chunked_document_embeddings[0]))\n",
        "\n",
        "\n",
        "# def generate_embeddings(documents: list[pd.DataFrame]) -> list[list[float]]:\n",
        "#     \"\"\"\n",
        "#     Generate embeddings for a list of DataFrame chunks, handling potential embedding service limits.\n",
        "\n",
        "#     Args:\n",
        "#         documents (list[pd.DataFrame]): A list of DataFrame chunks.\n",
        "\n",
        "#     Returns:\n",
        "#         list[list[float]]: A list containing lists of embeddings for each document.\n",
        "#     \"\"\"\n",
        "#     embed = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "#     embedded = []\n",
        "#     for df_chunk in documents:\n",
        "#       for index, row in df_chunk.iterrows():\n",
        "#         text_to_embed = row[\"question\"] + \" \" + row[\"answer\"]\n",
        "#         try:\n",
        "#           embedding = embed.embed_documents(text_to_embed)\n",
        "#           embedded.append(embedding)\n",
        "#         except Exception as e:\n",
        "#           print(f\"Embedding Error for row {index}: {e}\")\n",
        "#           continue\n",
        "\n",
        "#     return embedded\n",
        "\n",
        "# chunked_document_embeddings = generate_embeddings(documents=chunked_data)\n",
        "# print(\"Length of embeddings list:\", len(chunked_document_embeddings))"
      ],
      "metadata": {
        "id": "yG2YSg0_oyxc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Embeddings for Question-Answer Pairs (Without Chunking)"
      ],
      "metadata": {
        "id": "e7XmBbzuld0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# without chunking\n",
        "\n",
        "def generate_embeddings(data: pd.DataFrame) -> list[list[float]]:\n",
        "    \"\"\"\n",
        "    Generate embeddings for all question-answer pairs in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): A DataFrame with 'question' and 'answer' columns.\n",
        "\n",
        "    Returns:\n",
        "        list[list[float]]: A list of embedding lists, one embedding per question-answer pair.\n",
        "    \"\"\"\n",
        "    embed = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
        "    BATCH_SIZE = 50\n",
        "    embedded = []\n",
        "    texts_to_embed = []\n",
        "    for index, row in data.iterrows():\n",
        "        text_to_embed = row[\"question\"] + \" \" + row[\"answer\"]\n",
        "        texts_to_embed.append(text_to_embed)\n",
        "\n",
        "        # Embed in batches\n",
        "        if len(texts_to_embed) >= BATCH_SIZE:\n",
        "            embeddings = embed.embed_documents(texts_to_embed)\n",
        "            embedded.extend(embeddings)\n",
        "            texts_to_embed = []  # Reset the batch\n",
        "\n",
        "    # Embed any remaining texts\n",
        "    if texts_to_embed:\n",
        "        embeddings = embed.embed_documents(texts_to_embed)\n",
        "        embedded.extend(embeddings)\n",
        "\n",
        "    return embedded\n",
        "\n",
        "embeddings = generate_embeddings(data)"
      ],
      "metadata": {
        "id": "VX2MLblR0hBI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a function called `generate_embeddings` that computes embeddings for all question-answer pairs in a DataFrame without chunking the data. It initializes the GoogleGenerativeAIEmbeddings model using a specified model (\"models/embedding-001\") and the Google API key.\n",
        "\n",
        "Within the function, it iterates through each row of the DataFrame, combining the 'question' and 'answer' columns into a single text string. These text strings are added to a list called `texts_to_embed`.\n",
        "\n",
        "To optimize performance, the function embeds the text strings in batches, where the batch size is defined by the constant `BATCH_SIZE`. When the number of text strings in `texts_to_embed` reaches or exceeds `BATCH_SIZE`, they are embedded together using the `embed_documents` method. The embeddings are then appended to the `embedded` list, and `texts_to_embed` is reset to an empty list.\n",
        "\n",
        "After iterating through all rows in the DataFrame, the function embeds any remaining text strings in `texts_to_embed`. The resulting list of embeddings is returned as `embedded`."
      ],
      "metadata": {
        "id": "R63_RL4Olg1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining Embeddings with Data"
      ],
      "metadata": {
        "id": "-G1SaWo1lrK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_embeddings_and_data(data: pd.DataFrame, embeddings: list[list[float]]) -> pd.DataFrame:\n",
        "    \"\"\"Combines embeddings with a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): DataFrame with 'question' and 'answer' columns.\n",
        "        embeddings (list[list[float]]): List of embedding vectors.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame with embeddings and original data.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(data) != len(embeddings):\n",
        "        raise ValueError(\"Number of embeddings must match the number of data rows.\")\n",
        "\n",
        "    data['embeddings'] = embeddings\n",
        "    return data\n",
        "\n",
        "combined_data = combine_embeddings_and_data(data.copy(), embeddings)"
      ],
      "metadata": {
        "id": "g_xrW3JDXE5s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a function called `combine_embeddings_and_data` that merges embeddings with a DataFrame. It takes two arguments: `data`, which is a DataFrame containing the 'question' and 'answer' columns, and `embeddings`, which is a list of embedding vectors.\n",
        "\n",
        "Within the function, it first checks if the number of rows in the DataFrame matches the number of embedding vectors. If not, it raises a ValueError.\n",
        "\n",
        "Next, it adds a new column called 'embeddings' to the DataFrame and assigns the embedding vectors to this column. The DataFrame with embeddings included is then returned.\n",
        "\n",
        "Finally, the function is called to combine the original data (copied to avoid modifying the original DataFrame) with the embeddings, resulting in a new DataFrame called `combined_data`."
      ],
      "metadata": {
        "id": "PHFMafMLlvRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Short IDs and Combining Vectors with Text and Metadata"
      ],
      "metadata": {
        "id": "78ysxwZSl2jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def generate_short_id(question: str, answer: str) -> str:\n",
        "    \"\"\"Generates a short ID based on the question and answer using SHA-256 hash. \"\"\"\n",
        "    content = question + answer\n",
        "    hash_obj = hashlib.sha256()\n",
        "    hash_obj.update(content.encode(\"utf-8\"))\n",
        "    return hash_obj.hexdigest()\n",
        "\n",
        "\n",
        "def combine_vector_and_text(data: pd.DataFrame, embeddings: list[list[float]]) -> list[dict[str, any]]:\n",
        "    \"\"\"Combines embeddings, text, and metadata from a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): DataFrame with 'question' and 'answers' columns.\n",
        "        embeddings (list[list[float]]): List of lists containing embeddings.\n",
        "\n",
        "    Returns:\n",
        "        list[dict[str, any]]: List of dictionaries with 'id', 'values', and 'metadata'.\n",
        "    \"\"\"\n",
        "    if len(data) != len(embeddings):\n",
        "        raise ValueError(\"Number of embeddings must match the number of data rows.\")\n",
        "\n",
        "    data_with_metadata = []\n",
        "    for index, row in data.iterrows():\n",
        "        question = row[\"question\"]\n",
        "        answer = row[\"answer\"]\n",
        "        embedding = embeddings[index]\n",
        "\n",
        "        doc_id = generate_short_id(question, answer)\n",
        "\n",
        "        data_item = {\n",
        "            \"id\": doc_id,\n",
        "            \"values\": embedding,\n",
        "            \"metadata\": {\n",
        "                \"question\": question,\n",
        "                \"answer\": answer\n",
        "            }\n",
        "        }\n",
        "        data_with_metadata.append(data_item)\n",
        "\n",
        "    return data_with_metadata\n",
        "\n",
        "data_with_meta_data = combine_vector_and_text(data, embeddings)"
      ],
      "metadata": {
        "id": "u94RR1loXO_E"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet contains two functions: `generate_short_id` and `combine_vector_and_text`.\n",
        "\n",
        "#### `generate_short_id`:\n",
        "- This function generates a short ID based on the concatenation of a question and an answer using the SHA-256 hash algorithm.\n",
        "- It takes two arguments: `question` (string) and `answer` (string).\n",
        "- It concatenates the `question` and `answer`, hashes the result using SHA-256, and returns the hexadecimal digest of the hash.\n",
        "\n",
        "#### `combine_vector_and_text`:\n",
        "- This function combines embeddings, text, and metadata from a DataFrame.\n",
        "- It takes two arguments: `data`, which is a DataFrame with 'question' and 'answers' columns, and `embeddings`, which is a list of lists containing embeddings.\n",
        "- It iterates through each row of the DataFrame, extracting the question, answer, and embedding for each pair.\n",
        "- It generates a short ID for each pair using the `generate_short_id` function.\n",
        "- It creates a dictionary containing the ID, embedding values, and metadata (question and answer).\n",
        "- It appends each dictionary to a list.\n",
        "- It then returns list of dictionaries containing the combined data and metadata."
      ],
      "metadata": {
        "id": "QxR2bDs7l3pW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upserting Data to Pinecone Index"
      ],
      "metadata": {
        "id": "DC0_0l3gmTp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsert_data_to_pinecone(data_with_metadata: list[dict[str, any]]) -> None:\n",
        "    \"\"\"Upserts data with metadata into a Pinecone index in batches.\n",
        "\n",
        "    Args:\n",
        "        data_with_metadata (list[dict[str, any]]): List of dictionaries containing 'id', 'values', and 'metadata'.\n",
        "    \"\"\"\n",
        "    index = pc.Index(\"businesschatbot\")\n",
        "    BATCH_SIZE = 100\n",
        "\n",
        "    for i in range(0, len(data_with_metadata), BATCH_SIZE):\n",
        "        batch = data_with_metadata[i:i + BATCH_SIZE]\n",
        "        index.upsert(vectors=batch)\n",
        "\n",
        "upsert_data_to_pinecone(data_with_meta_data)"
      ],
      "metadata": {
        "id": "YzOu8Uc9aV1R"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet defines a function called `upsert_data_to_pinecone` that upserts data with metadata into a Pinecone index in batches.\n",
        "\n",
        "- It takes a list of dictionaries `data_with_metadata`, where each dictionary contains 'id', 'values', and 'metadata' fields.\n",
        "- It initializes a Pinecone index named \"businesschatbot\".\n",
        "- It specifies a batch size (`BATCH_SIZE`) of 100.\n",
        "- It iterates through the list of data with metadata in batches, where each batch contains `BATCH_SIZE` elements.\n",
        "- For each batch, it calls the `upsert` method of the Pinecone index to upsert the vectors (embeddings) with their corresponding metadata.\n",
        "- Calls the `upsert_data_to_pinecone` function with the `data_with_meta_data` list to upsert the combined data into the Pinecone index"
      ],
      "metadata": {
        "id": "VYZFshd2maR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Query"
      ],
      "metadata": {
        "id": "iU6CfCL4mlwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed Query\n",
        "\n",
        "def get_query_embeddings(query: str) -> list[float]:\n",
        "    \"\"\"Embeds a query using the GoogleGenerativeAIEmbeddings model.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query/question to embed.\n",
        "\n",
        "    Returns:\n",
        "        list[float]: A list representing the query's embedding.\n",
        "    \"\"\"\n",
        "    embed = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
        "    query_embedding = embed.embed_query(query)\n",
        "    return query_embedding\n",
        "\n",
        "\n",
        "query_embeddings = get_query_embeddings(query=str(data['question'][0]))\n",
        "query_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz0Q8JFpa5wD",
        "outputId": "ab4fe367-b0f5-4e0e-8a8b-116bba60b10c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0268475,\n",
              " -0.035075136,\n",
              " -0.09942184,\n",
              " -0.038361233,\n",
              " 0.034522563,\n",
              " 0.01574953,\n",
              " 0.0153615475,\n",
              " -0.020818792,\n",
              " 0.0075273346,\n",
              " 0.051213093,\n",
              " -0.033743806,\n",
              " 0.017856065,\n",
              " -0.041381054,\n",
              " 0.0069825253,\n",
              " -0.015233365,\n",
              " -0.08352683,\n",
              " 0.024915708,\n",
              " 0.027591094,\n",
              " -0.0001669012,\n",
              " 0.0077112177,\n",
              " 0.0014167358,\n",
              " 0.027923005,\n",
              " -0.013416919,\n",
              " 0.021074118,\n",
              " -0.008636853,\n",
              " 0.0033560507,\n",
              " -0.026263561,\n",
              " -0.050271165,\n",
              " -0.039655562,\n",
              " -0.010227287,\n",
              " -0.06812153,\n",
              " 0.05003489,\n",
              " -0.06416083,\n",
              " 0.012876017,\n",
              " -0.0053142314,\n",
              " -0.046686683,\n",
              " -0.03549387,\n",
              " 0.0027419839,\n",
              " -0.00055229926,\n",
              " 0.01127173,\n",
              " 0.0079386225,\n",
              " -0.03310727,\n",
              " -0.036755595,\n",
              " -0.021465521,\n",
              " -0.033145193,\n",
              " 0.0082884785,\n",
              " -0.03207378,\n",
              " 0.0007314973,\n",
              " -0.0019791457,\n",
              " -0.04785894,\n",
              " -0.0067082737,\n",
              " 0.023298126,\n",
              " 0.08859486,\n",
              " -0.042726774,\n",
              " 0.029860338,\n",
              " -0.059919327,\n",
              " 0.04979617,\n",
              " -0.014599413,\n",
              " 0.005972011,\n",
              " 0.018982958,\n",
              " 0.03149785,\n",
              " 0.013633364,\n",
              " 0.031204153,\n",
              " 0.019380791,\n",
              " -0.03622913,\n",
              " -0.084324785,\n",
              " -0.011131103,\n",
              " -0.015826844,\n",
              " 0.06912051,\n",
              " 0.015634688,\n",
              " -0.012224108,\n",
              " -0.0003530222,\n",
              " 0.052209545,\n",
              " 0.012035232,\n",
              " 0.018704064,\n",
              " -0.15390454,\n",
              " -0.019347744,\n",
              " 0.06830066,\n",
              " 0.06302958,\n",
              " -0.007913269,\n",
              " 0.04472373,\n",
              " -0.044230886,\n",
              " -0.0626547,\n",
              " -0.055067025,\n",
              " -0.08382588,\n",
              " 0.015506787,\n",
              " -0.03266386,\n",
              " -0.007091185,\n",
              " 0.009443394,\n",
              " 0.043102417,\n",
              " -0.023511002,\n",
              " 0.0020687354,\n",
              " 0.06259756,\n",
              " -0.03519027,\n",
              " -0.006122045,\n",
              " 0.08314031,\n",
              " -0.00029267496,\n",
              " -0.04409779,\n",
              " 0.008011931,\n",
              " -0.0015309032,\n",
              " -0.013442869,\n",
              " -0.017431734,\n",
              " -0.040511914,\n",
              " -0.029382166,\n",
              " 0.046859585,\n",
              " 0.032623384,\n",
              " 0.023137826,\n",
              " 0.049003772,\n",
              " -0.05130417,\n",
              " 0.019290216,\n",
              " -0.044306178,\n",
              " 0.0029257531,\n",
              " 0.015445204,\n",
              " -0.00045225184,\n",
              " 0.059534717,\n",
              " -0.009292102,\n",
              " 0.028411232,\n",
              " 0.06446412,\n",
              " 0.03429075,\n",
              " 0.05108852,\n",
              " 0.060413618,\n",
              " -0.038233355,\n",
              " 0.06583951,\n",
              " 0.018978229,\n",
              " 0.017413145,\n",
              " -0.03141065,\n",
              " 0.002382024,\n",
              " 0.008894256,\n",
              " 0.04852466,\n",
              " 0.0048519913,\n",
              " -0.042763606,\n",
              " -0.03317379,\n",
              " -0.039874427,\n",
              " 0.013302819,\n",
              " 0.017033007,\n",
              " 0.049640875,\n",
              " 0.004364082,\n",
              " -0.010607063,\n",
              " 0.026463106,\n",
              " -0.020998318,\n",
              " 0.0064382264,\n",
              " 0.03431689,\n",
              " 0.0066146096,\n",
              " 0.035121012,\n",
              " -0.0097873565,\n",
              " 0.050834592,\n",
              " -0.032491,\n",
              " 0.0029309338,\n",
              " 0.05903121,\n",
              " 0.00018930336,\n",
              " -0.0021019238,\n",
              " -0.0070588673,\n",
              " -0.035160422,\n",
              " -0.0021959061,\n",
              " 0.040522885,\n",
              " 0.009496092,\n",
              " -0.011696735,\n",
              " 0.017538799,\n",
              " 0.032597754,\n",
              " 0.0439645,\n",
              " 0.038804986,\n",
              " 0.010468363,\n",
              " 0.03532394,\n",
              " 0.015534131,\n",
              " -0.008235495,\n",
              " -0.047661316,\n",
              " -0.05016749,\n",
              " -0.015293132,\n",
              " -0.023373755,\n",
              " -0.010651855,\n",
              " 0.0012678361,\n",
              " 0.028850038,\n",
              " -0.07312817,\n",
              " -0.023752192,\n",
              " 0.017573847,\n",
              " -0.04602083,\n",
              " 0.022528348,\n",
              " 0.016079834,\n",
              " -0.061287705,\n",
              " -0.0046477583,\n",
              " -0.031637855,\n",
              " -0.039343115,\n",
              " 0.00428223,\n",
              " 0.028104283,\n",
              " 0.022668675,\n",
              " -0.081620835,\n",
              " 0.046288695,\n",
              " 0.020803135,\n",
              " -0.01576747,\n",
              " -0.018923873,\n",
              " -0.0057150577,\n",
              " 0.015434356,\n",
              " -0.046058465,\n",
              " -0.021894153,\n",
              " -0.009638966,\n",
              " 0.015442017,\n",
              " 0.016148558,\n",
              " 0.01915669,\n",
              " -0.004567989,\n",
              " -0.056777604,\n",
              " -0.01399222,\n",
              " 0.065461956,\n",
              " -0.017897474,\n",
              " 0.02288362,\n",
              " 0.021723494,\n",
              " -0.008472218,\n",
              " 0.024058735,\n",
              " -0.06505869,\n",
              " 0.002285254,\n",
              " 0.039945897,\n",
              " -0.01941398,\n",
              " 0.01999752,\n",
              " -0.046851728,\n",
              " -0.032057352,\n",
              " 0.039814413,\n",
              " -0.046839207,\n",
              " -0.0058705346,\n",
              " 0.034425147,\n",
              " 0.03476754,\n",
              " -0.020091232,\n",
              " -0.013681604,\n",
              " -0.009161403,\n",
              " -0.03450825,\n",
              " -0.018115874,\n",
              " -0.023000771,\n",
              " -0.0021979115,\n",
              " 0.01381189,\n",
              " 0.03072159,\n",
              " 0.009054431,\n",
              " -0.053075075,\n",
              " 0.020299312,\n",
              " 0.09593136,\n",
              " 0.022213992,\n",
              " -0.006418141,\n",
              " 0.122314975,\n",
              " -0.00058845064,\n",
              " 0.015861345,\n",
              " 0.0065893475,\n",
              " -0.02213376,\n",
              " 0.016877418,\n",
              " -0.049081776,\n",
              " 0.046337824,\n",
              " 0.025451943,\n",
              " 0.050785776,\n",
              " -0.06951255,\n",
              " -0.019652179,\n",
              " -0.030090893,\n",
              " 0.07062327,\n",
              " 0.0073907655,\n",
              " 0.06696313,\n",
              " -0.02334246,\n",
              " -0.026433874,\n",
              " -0.018479453,\n",
              " 0.009153735,\n",
              " -0.09784022,\n",
              " 0.03130318,\n",
              " -0.04773385,\n",
              " 0.0063774353,\n",
              " 0.01936917,\n",
              " -0.005108201,\n",
              " 0.07838386,\n",
              " 0.012897584,\n",
              " 0.0014452873,\n",
              " 0.0029071025,\n",
              " 0.0069516995,\n",
              " -0.038698588,\n",
              " -0.0066373106,\n",
              " -0.05139268,\n",
              " 0.0013553178,\n",
              " 0.02601433,\n",
              " 0.026627898,\n",
              " -0.012330069,\n",
              " 0.048153907,\n",
              " -0.00050617626,\n",
              " 0.005051076,\n",
              " 0.0045650853,\n",
              " -0.0019181138,\n",
              " 0.07007281,\n",
              " 0.017601464,\n",
              " -0.064108364,\n",
              " 0.006795571,\n",
              " 0.03185841,\n",
              " 0.028277468,\n",
              " -0.026485395,\n",
              " -0.03364168,\n",
              " -0.0126042655,\n",
              " -0.05917884,\n",
              " -0.022446778,\n",
              " -0.007102931,\n",
              " -0.08140202,\n",
              " -0.031615935,\n",
              " -0.030547978,\n",
              " 0.00343946,\n",
              " -0.08043511,\n",
              " -0.039070502,\n",
              " 0.020620724,\n",
              " -0.034513414,\n",
              " 0.05899457,\n",
              " 0.0064393333,\n",
              " -0.06820229,\n",
              " 0.012023034,\n",
              " -0.08186858,\n",
              " 0.00243416,\n",
              " -0.04168149,\n",
              " 0.028796842,\n",
              " 0.030791199,\n",
              " -0.015742918,\n",
              " -0.030845804,\n",
              " 0.0050505036,\n",
              " -0.010619085,\n",
              " 0.0016208396,\n",
              " -0.016403068,\n",
              " -0.05606641,\n",
              " 0.0076770117,\n",
              " 0.023269864,\n",
              " 0.055951726,\n",
              " -0.007854224,\n",
              " 0.026210776,\n",
              " -0.018196799,\n",
              " 0.04250989,\n",
              " 0.0055029043,\n",
              " 0.037481524,\n",
              " 0.031683464,\n",
              " 0.0027264522,\n",
              " 0.00982783,\n",
              " 0.051595025,\n",
              " -0.022060804,\n",
              " 0.022130761,\n",
              " -0.013981749,\n",
              " 0.0079681855,\n",
              " -0.01770368,\n",
              " 0.021787614,\n",
              " -0.04120329,\n",
              " 0.011216729,\n",
              " -0.013434388,\n",
              " 0.05391161,\n",
              " -0.081767745,\n",
              " -0.042951494,\n",
              " -0.031444848,\n",
              " -0.0058070715,\n",
              " -0.018839026,\n",
              " 0.016145688,\n",
              " -0.031405013,\n",
              " -0.013580816,\n",
              " 0.04610706,\n",
              " -0.018148364,\n",
              " -0.018596046,\n",
              " 0.029556114,\n",
              " 0.07780295,\n",
              " 0.07689019,\n",
              " 0.004682235,\n",
              " 0.059367485,\n",
              " -0.005176334,\n",
              " -0.00093860936,\n",
              " 0.019235734,\n",
              " -0.022580497,\n",
              " 0.037661564,\n",
              " -0.044235595,\n",
              " -0.005047953,\n",
              " -0.029849077,\n",
              " -0.004569975,\n",
              " 0.007875603,\n",
              " 0.020125963,\n",
              " -0.0040791743,\n",
              " 0.0077089425,\n",
              " -0.015495848,\n",
              " -0.017002428,\n",
              " 0.069502786,\n",
              " -0.0047031147,\n",
              " 0.064255945,\n",
              " 0.014619149,\n",
              " -0.016565831,\n",
              " 0.019292524,\n",
              " -0.015298476,\n",
              " 0.03342704,\n",
              " -0.014768556,\n",
              " -0.026821403,\n",
              " -0.056862984,\n",
              " 0.028272932,\n",
              " 0.04297246,\n",
              " 0.009601854,\n",
              " -0.0076041566,\n",
              " 0.033219412,\n",
              " 0.060588114,\n",
              " 0.013370349,\n",
              " -0.00798298,\n",
              " 0.053303633,\n",
              " 0.03542145,\n",
              " -0.018242063,\n",
              " 0.031561162,\n",
              " -0.06163239,\n",
              " 0.039693195,\n",
              " 0.060653273,\n",
              " -0.0052197124,\n",
              " 0.03497184,\n",
              " -0.03195475,\n",
              " -0.03696967,\n",
              " -0.02545022,\n",
              " 0.04396903,\n",
              " 0.008105492,\n",
              " -0.010927997,\n",
              " -0.057629623,\n",
              " -0.027777795,\n",
              " -0.012870858,\n",
              " -0.048673857,\n",
              " -0.019453822,\n",
              " -0.010283092,\n",
              " 0.0050170505,\n",
              " -0.029424673,\n",
              " -0.029134901,\n",
              " 0.01624112,\n",
              " 0.01935101,\n",
              " 0.020573063,\n",
              " -0.052921616,\n",
              " -0.025188372,\n",
              " 0.0032686156,\n",
              " 0.029410515,\n",
              " -0.023589337,\n",
              " 0.003592641,\n",
              " 0.0207989,\n",
              " -0.047396068,\n",
              " -0.0074409964,\n",
              " -0.010950026,\n",
              " -0.03653714,\n",
              " -0.091735326,\n",
              " -0.030830342,\n",
              " 0.05528319,\n",
              " 0.0305769,\n",
              " 0.008707976,\n",
              " 0.024579538,\n",
              " 0.03246865,\n",
              " 0.0014997752,\n",
              " -0.0116521,\n",
              " -0.009139575,\n",
              " -0.005009523,\n",
              " -0.048538897,\n",
              " -0.0043658935,\n",
              " 0.037943233,\n",
              " -0.020536875,\n",
              " -0.028058153,\n",
              " 0.07476586,\n",
              " 0.0011561689,\n",
              " 7.9544596e-05,\n",
              " -0.0088249715,\n",
              " -0.00043908638,\n",
              " -0.039685942,\n",
              " -0.02799686,\n",
              " -0.014441453,\n",
              " 0.05068802,\n",
              " -0.09325511,\n",
              " 0.032838438,\n",
              " -0.056618545,\n",
              " -0.018875625,\n",
              " -0.065261476,\n",
              " -0.052433465,\n",
              " -0.04869829,\n",
              " -0.007816257,\n",
              " 0.065502904,\n",
              " 0.010278037,\n",
              " -0.006476474,\n",
              " 0.017611692,\n",
              " -0.012759498,\n",
              " -0.022629393,\n",
              " -0.1296523,\n",
              " 0.01092959,\n",
              " 0.010299922,\n",
              " 0.01014097,\n",
              " -0.023219917,\n",
              " 0.020795997,\n",
              " 0.02978227,\n",
              " -0.0022975774,\n",
              " -0.0078305425,\n",
              " 0.0032112682,\n",
              " -0.009874517,\n",
              " -0.02264988,\n",
              " -0.05811012,\n",
              " -0.06959856,\n",
              " 0.049926504,\n",
              " -0.018505875,\n",
              " -0.028644444,\n",
              " 0.03543722,\n",
              " 0.011985357,\n",
              " -0.02287251,\n",
              " 0.034066975,\n",
              " -0.0017366438,\n",
              " 0.016270477,\n",
              " 0.0033047765,\n",
              " -0.033006206,\n",
              " -0.012916956,\n",
              " 0.06106911,\n",
              " 0.04616013,\n",
              " -0.023575503,\n",
              " -0.011391492,\n",
              " -0.036803104,\n",
              " -0.026172986,\n",
              " 0.01748789,\n",
              " -0.022183737,\n",
              " 0.031615928,\n",
              " 0.031574726,\n",
              " 0.02854794,\n",
              " -0.027043456,\n",
              " -0.018111097,\n",
              " 0.01915876,\n",
              " -0.033719532,\n",
              " 0.025280606,\n",
              " -0.033043038,\n",
              " -0.01012547,\n",
              " 0.02925404,\n",
              " 0.040887557,\n",
              " -0.016635831,\n",
              " 0.009689884,\n",
              " -0.011825842,\n",
              " -0.031287305,\n",
              " -0.0041687717,\n",
              " 0.07630544,\n",
              " -0.018418785,\n",
              " -0.0061513837,\n",
              " -0.0012228258,\n",
              " -0.024966111,\n",
              " -0.0044758855,\n",
              " 0.015035442,\n",
              " -0.015871689,\n",
              " -0.1129097,\n",
              " 0.007882199,\n",
              " 0.034701753,\n",
              " -0.045592934,\n",
              " 0.013768661,\n",
              " 0.00373844,\n",
              " -0.04800193,\n",
              " 0.039484717,\n",
              " -0.05454101,\n",
              " 0.053255137,\n",
              " -0.087413214,\n",
              " 0.0033504888,\n",
              " -0.0056983004,\n",
              " 0.01801589,\n",
              " 0.020499032,\n",
              " 0.022870753,\n",
              " -0.030833852,\n",
              " -0.015238396,\n",
              " 0.03727983,\n",
              " -0.002074579,\n",
              " 0.029614054,\n",
              " 0.0061454247,\n",
              " -0.043150175,\n",
              " 0.021761134,\n",
              " -0.014175937,\n",
              " -0.08260944,\n",
              " 0.0064533385,\n",
              " 0.018530859,\n",
              " -0.024036568,\n",
              " 0.04615669,\n",
              " 0.028222313,\n",
              " -0.030958598,\n",
              " 0.024347031,\n",
              " -0.017182022,\n",
              " 0.0072511467,\n",
              " -0.0051695644,\n",
              " 0.012335922,\n",
              " -0.035888363,\n",
              " -0.012107865,\n",
              " 0.0034395885,\n",
              " -0.016098563,\n",
              " -0.011334132,\n",
              " 0.053923972,\n",
              " 0.025661642,\n",
              " -0.018679567,\n",
              " -0.030184422,\n",
              " 0.06973192,\n",
              " -0.015188871,\n",
              " -0.010069705,\n",
              " 0.017279895,\n",
              " 0.02833171,\n",
              " -0.024427751,\n",
              " 0.043133684,\n",
              " -0.017203754,\n",
              " -0.087021254,\n",
              " -0.011513605,\n",
              " 0.0022732562,\n",
              " 5.2606898e-05,\n",
              " 0.067322746,\n",
              " -0.0038170505,\n",
              " -0.0027661142,\n",
              " 0.07710811,\n",
              " -0.015066269,\n",
              " 0.01820558,\n",
              " 0.08375317,\n",
              " 0.045237463,\n",
              " 0.019208264,\n",
              " 0.012895783,\n",
              " -0.044310696,\n",
              " 0.030209467,\n",
              " -0.041127846,\n",
              " 0.033298835,\n",
              " 0.014852317,\n",
              " 0.0076577365,\n",
              " 0.005056614,\n",
              " -0.034147948,\n",
              " -0.03267917,\n",
              " -0.013821967,\n",
              " 0.0032757423,\n",
              " -0.00067429617,\n",
              " 0.057984546,\n",
              " -0.013233918,\n",
              " 0.08317786,\n",
              " 0.034465805,\n",
              " 0.0011868576,\n",
              " 0.0050092917,\n",
              " 0.06509451,\n",
              " 0.044365082,\n",
              " -0.010442911,\n",
              " -0.016447684,\n",
              " 0.030142983,\n",
              " -0.01875157,\n",
              " -0.040877514,\n",
              " -0.0829542,\n",
              " 0.06577393,\n",
              " -0.026653634,\n",
              " -0.010146187,\n",
              " -0.06810676,\n",
              " -0.01496303,\n",
              " 0.022349583,\n",
              " 0.03929738,\n",
              " -0.01615331,\n",
              " 0.0064046048,\n",
              " 0.0120646525,\n",
              " -0.025495797,\n",
              " -0.025731076,\n",
              " 0.07025798,\n",
              " 0.027779177,\n",
              " 0.05482414,\n",
              " 0.04758515,\n",
              " -0.040889043,\n",
              " 0.024450848,\n",
              " -0.050822873,\n",
              " 0.019793497,\n",
              " 0.00071256416,\n",
              " 0.010103449,\n",
              " 0.02718436,\n",
              " -0.019693453,\n",
              " -0.07313813,\n",
              " 0.0076577403,\n",
              " 0.0005471397,\n",
              " 0.030634133,\n",
              " -0.051113226,\n",
              " 0.054598004,\n",
              " 0.035152648,\n",
              " -0.06149616,\n",
              " -0.03142619,\n",
              " -0.02732566,\n",
              " -0.014825011,\n",
              " 0.008152507,\n",
              " 0.017972976,\n",
              " -0.006091,\n",
              " 0.039583676,\n",
              " -0.007681333,\n",
              " -0.016321199,\n",
              " -0.034294456,\n",
              " 0.06480254,\n",
              " -0.014334137,\n",
              " -0.04756144,\n",
              " -0.020896468,\n",
              " -0.01310221,\n",
              " -0.012344705,\n",
              " 0.0013868792,\n",
              " 0.0025029925,\n",
              " -0.028588057,\n",
              " -0.10783858,\n",
              " -0.03387022,\n",
              " 0.02569924,\n",
              " -0.07896084,\n",
              " 0.049088605,\n",
              " 0.03997603,\n",
              " -0.0084189335,\n",
              " 0.03703963,\n",
              " 0.008405096,\n",
              " -0.011099022,\n",
              " -0.015041027,\n",
              " 0.016054103,\n",
              " 0.037561,\n",
              " 0.03991148,\n",
              " -0.0077400473,\n",
              " -0.024273416,\n",
              " 0.029871317,\n",
              " 0.027549392,\n",
              " 0.03621649,\n",
              " -0.010525152,\n",
              " 0.015897924,\n",
              " -0.020176867,\n",
              " -0.031557743,\n",
              " -0.01813319,\n",
              " -0.05380637,\n",
              " -0.0061784806,\n",
              " 0.03182773,\n",
              " 0.041403405,\n",
              " 0.023309076,\n",
              " -0.012075233,\n",
              " -0.009901257,\n",
              " -0.0014382221,\n",
              " 0.008071118,\n",
              " -0.011630296,\n",
              " -0.040707923,\n",
              " 0.0043652146,\n",
              " 0.04798933,\n",
              " 0.012946534,\n",
              " -0.0017679161,\n",
              " 0.03621514,\n",
              " 0.031507652,\n",
              " 0.024547104,\n",
              " 0.035873406,\n",
              " 0.03383132,\n",
              " -0.051462963,\n",
              " -0.012889972,\n",
              " 0.06508773,\n",
              " 0.004309905,\n",
              " -0.060937226,\n",
              " 0.025621578,\n",
              " 0.044790298,\n",
              " -0.019759972,\n",
              " 0.060548156,\n",
              " 0.04513417,\n",
              " 0.021352889,\n",
              " 0.025062842,\n",
              " 0.011326302,\n",
              " -0.030071318,\n",
              " 0.044169895,\n",
              " -0.019691795,\n",
              " -0.019608187,\n",
              " 0.016581245,\n",
              " -0.029762583,\n",
              " 0.053339515,\n",
              " -0.0014854193,\n",
              " -0.019691622,\n",
              " 0.033376433,\n",
              " -0.040060647,\n",
              " 0.080319926,\n",
              " 0.05121096,\n",
              " 0.06990117,\n",
              " -0.030899232,\n",
              " -0.052988164,\n",
              " -0.035659812,\n",
              " 0.0023051426,\n",
              " -0.014073585,\n",
              " 0.038008105,\n",
              " -0.003133486,\n",
              " -0.033103593,\n",
              " -0.021667058,\n",
              " -0.05224414,\n",
              " -0.007878699,\n",
              " -0.028559057,\n",
              " -0.049904898,\n",
              " 0.0031174484,\n",
              " -0.01336381,\n",
              " -0.0072853775,\n",
              " 0.044167526,\n",
              " -0.033660263,\n",
              " -0.0009609067,\n",
              " -0.03684004,\n",
              " 0.0095289545,\n",
              " -0.004244255,\n",
              " -0.0543479,\n",
              " 0.026388746,\n",
              " -0.019044187,\n",
              " -0.0052251555,\n",
              " 0.009623554,\n",
              " -0.0030246805,\n",
              " -0.033068694,\n",
              " 0.02250654]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet defines a function called `get_query_embeddings` that embeds a query using the GoogleGenerativeAIEmbeddings model.\n",
        "\n",
        "- It takes a single argument `query`, which is a string representing the query or question to be embedded.\n",
        "- It initializes the GoogleGenerativeAIEmbeddings model with a specified model (\"models/embedding-001\") and the Google API key.\n",
        "- It calls the `embed_query` method of the embedding model to embed the provided query.\n",
        "- The function returns a list representing the embedding of the query."
      ],
      "metadata": {
        "id": "JbJnFY3xmnP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Querying the Database"
      ],
      "metadata": {
        "id": "XXkUvPo-m09p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the Database\n",
        "\n",
        "def query_pinecone_index(\n",
        "    query_embeddings: list[float], top_k: int = 2, include_metadata: bool = True\n",
        ") -> list[dict[str, any]]:\n",
        "    \"\"\"Queries a Pinecone index and returns relevant results.\n",
        "\n",
        "    Args:\n",
        "        query_embeddings (list[float]): The embedding of the query.\n",
        "        top_k (int): Number of nearest neighbors to retrieve (default: 2).\n",
        "        include_metadata (bool): Whether to include metadata in the results (default: True).\n",
        "\n",
        "    Returns:\n",
        "        list[dict[str, any]]: A list of dictionaries, each containing the 'id', 'values' (embedding), and 'metadata' of a retrieved result.\n",
        "    \"\"\"\n",
        "    index = pc.Index(\"businesschatbot\")\n",
        "    results = index.query(\n",
        "        namespace='',\n",
        "        vector=query_embeddings,\n",
        "        top_k=top_k,\n",
        "        include_metadata=include_metadata\n",
        "    )\n",
        "\n",
        "    return results.matches\n",
        "\n",
        "answers = query_pinecone_index(query_embeddings=query_embeddings)\n",
        "answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvXv5yeNa5r4",
        "outputId": "9cae987e-7f2c-491c-cb19-ae1cf8e98905"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '924c91af3a25ddd8aa1256a9fe406f8f00b41b36ddef24d49048344926e0af19',\n",
              "  'metadata': {'answer': \"I've understood you have a question regarding \"\n",
              "                         \"canceling order [ENTITY_ORDER_NUMBER], and I'm here \"\n",
              "                         'to provide you with the information you need. Please '\n",
              "                         \"go ahead and ask your question, and I'll do my best \"\n",
              "                         'to assist you.',\n",
              "               'question': 'question about cancelling order '\n",
              "                           '[ENTITY_ORDER_NUMBER]'},\n",
              "  'score': 0.939645469,\n",
              "  'values': []},\n",
              " {'id': 'e85efc854c40e6ce165a5789a65c7ab772a7ceabca5a7cf6fb70da3da50ad1ed',\n",
              "  'metadata': {'answer': \"I've realized you have a question regarding canceling \"\n",
              "                         \"order [ENTITY_ORDER_NUMBER]. I'm here to provide you \"\n",
              "                         'with the information you need. Please go ahead and '\n",
              "                         \"let me know what specific question you have, and I'll \"\n",
              "                         'be happy to assist you further.',\n",
              "               'question': 'question about cancelling order '\n",
              "                           '[ENTITY_ORDER_NUMBER]'},\n",
              "  'score': 0.939420521,\n",
              "  'values': []}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet defines a function called `query_pinecone_index` that queries a Pinecone index and returns relevant results.\n",
        "\n",
        "- It takes three arguments: `query_embeddings`, which is the embedding of the query, `top_k` (default: 2), which specifies the number of nearest neighbors to retrieve, and `include_metadata` (default: True), which determines whether metadata should be included in the results.\n",
        "- It initializes my Pinecone index, named \"businesschatbot\".\n",
        "- It calls the `query` method of the index to perform the actual query.\n",
        "- The `query` method takes the namespace (an empty string in this case), the vector representation of the query (`query_embeddings`), the number of nearest neighbors to retrieve (`top_k`), and whether to include metadata in the results (`include_metadata`).\n",
        "- The function returns the matches found in the index, each represented as a dictionary containing the 'id', 'values' (embedding), and 'metadata' of a retrieved result."
      ],
      "metadata": {
        "id": "UjkdTQWqm5Zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Langchain for Better Query Responses"
      ],
      "metadata": {
        "id": "J9ok6_hp42br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = Gemini(model=\"models/gemini-pro\", temperature=0, google_api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "hT4GKoGEWLno"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract answer text\n",
        "def extract_answer_texts(answers: list[dict[str, any]]) -> str:\n",
        "    \"\"\"Extracts answer texts from retrieved results.\"\"\"\n",
        "    return \" \".join(answer['metadata']['answer'] for answer in answers)\n",
        "\n",
        "# Generate improved response\n",
        "def better_query_response(prompt: str) -> str:\n",
        "    return llm(prompt)"
      ],
      "metadata": {
        "id": "Ek9uPaGUjPWC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = query_pinecone_index(query_embeddings, top_k=5)\n",
        "answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrLjFA4FWx6j",
        "outputId": "68335895-6209-48c0-9664-7e1fc8e4d0de"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '924c91af3a25ddd8aa1256a9fe406f8f00b41b36ddef24d49048344926e0af19',\n",
              "  'metadata': {'answer': \"I've understood you have a question regarding \"\n",
              "                         \"canceling order [ENTITY_ORDER_NUMBER], and I'm here \"\n",
              "                         'to provide you with the information you need. Please '\n",
              "                         \"go ahead and ask your question, and I'll do my best \"\n",
              "                         'to assist you.',\n",
              "               'question': 'question about cancelling order '\n",
              "                           '[ENTITY_ORDER_NUMBER]'},\n",
              "  'score': 0.939645469,\n",
              "  'values': []},\n",
              " {'id': 'e85efc854c40e6ce165a5789a65c7ab772a7ceabca5a7cf6fb70da3da50ad1ed',\n",
              "  'metadata': {'answer': \"I've realized you have a question regarding canceling \"\n",
              "                         \"order [ENTITY_ORDER_NUMBER]. I'm here to provide you \"\n",
              "                         'with the information you need. Please go ahead and '\n",
              "                         \"let me know what specific question you have, and I'll \"\n",
              "                         'be happy to assist you further.',\n",
              "               'question': 'question about cancelling order '\n",
              "                           '[ENTITY_ORDER_NUMBER]'},\n",
              "  'score': 0.939420521,\n",
              "  'values': []},\n",
              " {'id': '0fd859246a7ba4242a6216556864743e02feae88f8bc2223964620e2710d6bba',\n",
              "  'metadata': {'answer': \"I've understood you have a question about canceling \"\n",
              "                         'order [ENTITY_ORDER_NUMBER]. How can I assist you?',\n",
              "               'question': 'question about canceling order '\n",
              "                           '[ENTITY_ORDER_NUMBER]'},\n",
              "  'score': 0.936810613,\n",
              "  'values': []},\n",
              " {'id': '0d0fbc926f1ec4cd21890331567f11bd9812c091329b125412b46054d6b425bd',\n",
              "  'metadata': {'answer': 'I understand you have a question regarding canceling '\n",
              "                         \"order [ENTITY_ORDER_NUMBER]. I'm here to assist you \"\n",
              "                         'and provide the information you need. Could you '\n",
              "                         'please clarify what specific question you have about '\n",
              "                         'canceling this order? This will help me to provide '\n",
              "                         'you with a more accurate and tailored answer. Thank '\n",
              "                         'you.',\n",
              "               'question': 'question about canceling order '\n",
              "                           '[ENTITY_ORDER_NUMBER]'},\n",
              "  'score': 0.936456382,\n",
              "  'values': []},\n",
              " {'id': 'b76da8dac03998699b4a6d9ee065db786ae8c747a117294e5f3e2fcb4333b332',\n",
              "  'metadata': {'answer': \"I've understood, you have a question about canceling \"\n",
              "                         'your order with the order number '\n",
              "                         '[ENTITY_ORDER_NUMBER]. How can I assist you?',\n",
              "               'question': 'i have a question about cancelling order '\n",
              "                           '[ENTITY_ORDER_NUMBER]'},\n",
              "  'score': 0.933028162,\n",
              "  'values': []}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_answer = extract_answer_texts(answers)\n",
        "text_answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "9UT49YASXFoJ",
        "outputId": "176b2c1b-43df-4d43-a652-47d717b16dca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I've understood you have a question regarding canceling order [ENTITY_ORDER_NUMBER], and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you. I've realized you have a question regarding canceling order [ENTITY_ORDER_NUMBER]. I'm here to provide you with the information you need. Please go ahead and let me know what specific question you have, and I'll be happy to assist you further. I've understood you have a question about canceling order [ENTITY_ORDER_NUMBER]. How can I assist you? I understand you have a question regarding canceling order [ENTITY_ORDER_NUMBER]. I'm here to assist you and provide the information you need. Could you please clarify what specific question you have about canceling this order? This will help me to provide you with a more accurate and tailored answer. Thank you. I've understood, you have a question about canceling your order with the order number [ENTITY_ORDER_NUMBER]. How can I assist you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"{text_answer} Using the provided information, give me a better and summarized answer\"\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "zZM6z6-qXWOY",
        "outputId": "29fe7885-b189-41fa-d962-6dba0d66b303"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I've understood you have a question regarding canceling order [ENTITY_ORDER_NUMBER], and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you. I've realized you have a question regarding canceling order [ENTITY_ORDER_NUMBER]. I'm here to provide you with the information you need. Please go ahead and let me know what specific question you have, and I'll be happy to assist you further. I've understood you have a question about canceling order [ENTITY_ORDER_NUMBER]. How can I assist you? I understand you have a question regarding canceling order [ENTITY_ORDER_NUMBER]. I'm here to assist you and provide the information you need. Could you please clarify what specific question you have about canceling this order? This will help me to provide you with a more accurate and tailored answer. Thank you. I've understood, you have a question about canceling your order with the order number [ENTITY_ORDER_NUMBER]. How can I assist you? Using the provided information, give me a better and summarized answer\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('models/gemini-pro')\n",
        "response = model.generate_content(prompt)"
      ],
      "metadata": {
        "id": "sWhoIKABYOqw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=str(data['question'][2])\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT9tHWDYgR3f",
        "outputId": "a294dcaf-b319-476d-d05d-47521b02d654"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i need help cancelling puchase [ENTITY_ORDER_NUMBER]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are a customer support assistant AI, your primary goal is to provide efficient and effective assistance to users seeking help or information regarding a product, service, or platform. Your interactions should be polite, empathetic, and tailored to the specific needs of the customer.\n",
        "\"\"\"\n",
        "SYSTEM_PROMPT"
      ],
      "metadata": {
        "id": "m3ni1kwNcD1_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b242bc0b-dfba-4095-8ffd-d40f9c7d509b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are a customer support assistant AI, your primary goal is to provide efficient and effective assistance to users seeking help or information regarding a product, service, or platform. Your interactions should be polite, empathetic, and tailored to the specific needs of the customer.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"{SYSTEM_PROMPT}\\n\\nNow using this answer: {text_answer}\\n\\n Provide a support based on this question{query}\"\n",
        "prompt"
      ],
      "metadata": {
        "id": "WdtzLgA_czZB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0940075d-e47f-489d-f191-11c9a780f7d0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You are a customer support assistant AI, your primary goal is to provide efficient and effective assistance to users seeking help or information regarding a product, service, or platform. Your interactions should be polite, empathetic, and tailored to the specific needs of the customer.\\n\\n\\nNow using this answer: I've understood you have a question regarding canceling order [ENTITY_ORDER_NUMBER], and I'm here to provide you with the information you need. Please go ahead and ask your question, and I'll do my best to assist you. I've realized you have a question regarding canceling order [ENTITY_ORDER_NUMBER]. I'm here to provide you with the information you need. Please go ahead and let me know what specific question you have, and I'll be happy to assist you further. I've understood you have a question about canceling order [ENTITY_ORDER_NUMBER]. How can I assist you? I understand you have a question regarding canceling order [ENTITY_ORDER_NUMBER]. I'm here to assist you and provide the information you need. Could you please clarify what specific question you have about canceling this order? This will help me to provide you with a more accurate and tailored answer. Thank you. I've understood, you have a question about canceling your order with the order number [ENTITY_ORDER_NUMBER]. How can I assist you?\\n\\n Provide a support based on this questioni need help cancelling puchase [ENTITY_ORDER_NUMBER]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CL_gCCICaaaq",
        "outputId": "48c810d0-d182-4b4c-870c-42549d6e5aeb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I've understood, you have a question about canceling your order with the order number [ENTITY_ORDER_NUMBER]. How can I assist you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final_answer = better_query_response(prompt)\n",
        "# print(final_answer)"
      ],
      "metadata": {
        "id": "fIHDXmdMWTzX"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code exp\n",
        "\n",
        "- It first imports the `PromptTemplate` class from `langchain.prompts`.\n",
        "- It initializes a Gemini model (`llm`) using a specified model (\"models/gemini-pro\"), setting the temperature parameter to 0, and providing the Google API key for authentication.\n",
        "- The `extract_answer_texts` function extracts answer texts from the retrieved results. It takes a list of retrieved results (`answers`) and returns a string containing all the answer texts concatenated together.\n",
        "- The `better_query_response` function generates an improved response using Langchain. It takes a prompt as input, passes it through the Gemini model, and returns the generated response.\n",
        "- The `query_pinecone_index` function is called to retrieve the top 5 answers from the Pinecone index based on the query embeddings.\n",
        "- The answer texts are extracted from the retrieved results using the `extract_answer_texts` function.\n",
        "- A prompt is constructed using the extracted answer texts, asking for a better and summarized answer."
      ],
      "metadata": {
        "id": "kJfB1z8C45Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY) # Initialize embeddings model\n",
        "# llm = Gemini(model=\"models/gemini-pro\", temperature=0, google_api_key=GOOGLE_API_KEY) # Initialize the Gemini LLM\n",
        "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True) # Set up conversational memory"
      ],
      "metadata": {
        "id": "2F8NHfTIwKXK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}